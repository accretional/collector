# Collector

A gRPC + Protocol Buffers framework for building distributed, dynamic RPC systems with built-in service discovery, type safety, and a powerful ORM for protobuf messages.

## What is Collector?

Collector is a distributed programming platform that combines:
- **Service Registry**: Type-safe registration and validation of gRPC services
- **Collections**: ORM-like storage for protobuf messages with full-text search
- **Dynamic Dispatch**: Transparent distributed RPC routing across clusters
- **Reflection & Discovery**: Runtime service introspection and dynamic invocation

It enables you to register and update protobuf messages and gRPC services at runtime, create "Collections" (tables + API servers) of any proto type, and dynamically dispatch RPC calls across a distributed systemâ€”all with strong typing and validation.

## Architecture

### Single Collector

Each collector runs **one gRPC server** with **all services** registered:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Collector Instance              â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Single gRPC Server             â”‚ â”‚
â”‚  â”‚    (port 50051)                   â”‚ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€ CollectorRegistry            â”‚ â”‚
â”‚  â”‚  â”œâ”€ CollectionService            â”‚ â”‚
â”‚  â”‚  â”œâ”€ CollectiveDispatcher         â”‚ â”‚
â”‚  â”‚  â””â”€ CollectionRepo                â”‚ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚  Registry Validation: ENABLED    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Collector Cluster

Multiple collectors connect to form a distributed system:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collector 1     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Collector 2     â”‚
â”‚  localhost:50051 â”‚         â”‚  localhost:50052 â”‚
â”‚                  â”‚         â”‚                  â”‚
â”‚  All 4 services  â”‚         â”‚  All 4 services  â”‚
â”‚  With validation â”‚         â”‚  With validation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                            â–²
        â”‚                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
              Dispatcher
              connects and
              routes between
```

### Service-to-Service Communication

Services communicate via **gRPC loopback** even when co-located:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Single gRPC Server (port 50051)        â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Dispatcher  â”‚ â”€â”€â”€â”€â”€>  â”‚   Registry   â”‚    â”‚
â”‚  â”‚              â”‚  gRPC   â”‚              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  call   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚              via loopback             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                            â–¼                   â”‚
â”‚                    localhost:50051             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ (actual gRPC call)
                            â–¼
                    gRPC validation interceptor
                            â”‚
                            â–¼
                    Registry.ValidateMethod()
```

**Why loopback?**
- âœ… Validates server wiring (ensures all services properly registered)
- âœ… Consistent behavior (same code path as remote calls)
- âœ… Full gRPC features (interceptors, middleware, error handling)
- âœ… Type safety (registry validation applies)

## Core Services

### 1. CollectorRegistry

**Purpose**: Centralized service and type registry

**Capabilities:**
- Register protobuf message types and gRPC services
- Validate RPC calls against registered types
- Dynamic service discovery and lookup
- Namespace-based isolation

**Key RPCs:**
- `RegisterProto` / `RegisterService` - Register types
- `LookupService` / `ValidateMethod` - Query registry
- `ListServices` - Discover available services

**Documentation**: [pkg/registry/README.md](pkg/registry/README.md)

### 2. CollectionService

**Purpose**: ORM-like storage for protobuf messages

**Capabilities:**
- CRUD operations (Create, Get, Update, Delete, List)
- Full-text search (SQLite FTS5)
- JSONB filtering for complex queries
- File attachments (hierarchical file storage)
- Custom RPC handlers
- Batch operations

**Key RPCs:**
- `Create` / `Get` / `Update` / `Delete` / `List` - CRUD
- `Search` - Full-text + JSONB queries
- `Invoke` - Custom method execution
- `Batch` - Multi-operation transactions

**Documentation**: [pkg/collection/README.md](pkg/collection/README.md)

### 3. CollectiveDispatcher

**Purpose**: Distributed RPC routing

**Capabilities:**
- Connect collectors into a mesh network
- Route requests to appropriate collector
- Execute service methods locally or remotely
- Namespace-aware routing
- Registry-validated execution

**Key RPCs:**
- `Connect` - Establish collector-to-collector links
- `Serve` - Execute local service methods
- `Dispatch` - Smart request routing (local or remote)

**Documentation**: [pkg/dispatch/README.md](pkg/dispatch/README.md)

### 4. CollectionRepo

**Purpose**: Multi-collection management

**Capabilities:**
- Create collections dynamically
- Discover collections by namespace, message type, or labels
- Route requests to appropriate collection
- Search across multiple collections
- **ğŸ†• Backup and restore collections** (point-in-time snapshots)
- **ğŸ†• Clone collections** (local and remote replication)
- **ğŸ†• Fetch collections** (pull from remote collectors)

**Key RPCs:**
- `CreateCollection` - Create new collection
- `Discover` - Find collections
- `Route` - Get collection endpoint
- `SearchCollections` - Cross-collection search
- **ğŸ†• `BackupCollection`** - Create point-in-time backup
- **ğŸ†• `RestoreBackup`** - Restore from backup
- **ğŸ†• `ListBackups` / `DeleteBackup` / `VerifyBackup`** - Backup management
- **ğŸ†• `Clone`** - Clone collection (local or remote)
- **ğŸ†• `Fetch`** - Pull collection from remote collector

**Documentation**:
- [pkg/collection/README.md](pkg/collection/README.md#collectionrepo---multi-collection-management)
- **ğŸ†• [Backup API Guide](docs/features/backup-api.md)** - Complete backup documentation
- **ğŸ†• [Clone & Fetch Guide](docs/features/clone-and-fetch.md)** - Replication and migration

## Quick Start

### Running a Collector

```bash
# Run the server
go run ./cmd/server/main.go
```

Output:
```
Starting Collector (ID: collector-001, Namespace: production)
âœ“ Registry server created
âœ“ Registered CollectionService in namespace 'production'
âœ“ Registered CollectiveDispatcher in namespace 'production'
âœ“ Registered CollectionRepo in namespace 'production'
âœ“ Collection repository created
âœ“ Dispatcher created with gRPC-based registry validation

========================================
Collector collector-001 running on localhost:50051
All services available:
  - CollectorRegistry
  - CollectionService
  - CollectiveDispatcher
  - CollectionRepo
Namespace: production
Registry validation: ENABLED
========================================
Press Ctrl+C to shutdown
```

### Client Example

```go
package main

import (
    "context"
    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
    pb "github.com/accretional/collector/gen/collector"
)

func main() {
    // Connect to collector
    conn, _ := grpc.Dial("localhost:50051", grpc.WithInsecure())
    defer conn.Close()

    ctx := context.Background()

    // 1. Create a collection
    repoClient := pb.NewCollectionRepoClient(conn)
    createResp, _ := repoClient.CreateCollection(ctx, &pb.CreateCollectionRequest{
        Collection: &pb.Collection{
            Namespace:   "production",
            Name:        "users",
            MessageType: "collector.User",
        },
    })

    // 2. Insert a record
    collectionClient := pb.NewCollectionServiceClient(conn)
    user := &pb.User{Id: "user-123", Name: "Alice", Email: "alice@example.com"}
    createResp, _ := collectionClient.Create(ctx, &pb.CreateRequest{
        Collection: &pb.Collection{Namespace: "production", Name: "users"},
        Record:     &pb.Record{Id: "user-123", Data: marshalToAny(user)},
    })

    // 3. Search records
    searchResp, _ := collectionClient.Search(ctx, &pb.SearchRequest{
        Collection: &pb.Collection{Namespace: "production", Name: "users"},
        Query:      "alice",
        Limit:      10,
    })

    // 4. Connect to another collector
    dispatcherClient := pb.NewCollectiveDispatcherClient(conn)
    connectResp, _ := dispatcherClient.Connect(ctx, &pb.ConnectRequest{
        CollectorId: "collector-001",
        Address:     "localhost:50051",
        Namespaces:  []string{"production"},
    })

    // 5. Dispatch a request (routes automatically)
    dispatchResp, _ := dispatcherClient.Dispatch(ctx, &pb.DispatchRequest{
        Namespace:  "production",
        Service:    &pb.ServiceTypeRef{ServiceName: "CollectionService"},
        MethodName: "Get",
        Input:      getRequestAny,
    })
}
```

## Key Features

### Namespace-Based Isolation

Everything in Collector is namespaced:
- **Multi-tenancy**: Different tenants have isolated data and services
- **Environment separation**: Dev/staging/prod with different configurations
- **Feature flags**: Enable/disable services per namespace
- **Version management**: Run multiple versions simultaneously

```go
// Register service in production namespace
registry.RegisterCollectionService(ctx, registryServer, "production")

// Register different version in staging
registry.RegisterCollectionServiceV2(ctx, registryServer, "staging")
```

### Type-Safe RPC Validation

All RPCs are validated against the registry before execution:

```go
// Create server with automatic validation
grpcServer := registry.NewServerWithValidation(registryServer, "production")

// Register service
pb.RegisterCollectionServiceServer(grpcServer, collectionServer)

// Unregistered RPCs are automatically rejected with codes.Unimplemented
```

### Dynamic Service Discovery

Query available services at runtime:

```go
// List all services in a namespace
services, _ := registryClient.ListServices(ctx, &pb.ListServicesRequest{
    Namespace: "production",
})

for _, service := range services {
    fmt.Printf("Service: %s\n", service.ServiceName)
    fmt.Printf("Methods: %v\n", service.MethodNames)
}
```

### Full-Text Search

SQLite FTS5-powered search across protobuf messages:

```go
// Search with full-text query
results, _ := client.Search(ctx, &pb.SearchRequest{
    Collection: &pb.Collection{Namespace: "production", Name: "users"},
    Query:      "senior engineer",
    Limit:      20,
})

// Combined with JSONB filtering
results, _ := client.Search(ctx, &pb.SearchRequest{
    Collection: &pb.Collection{Namespace: "production", Name: "users"},
    Query:      "engineer",
    Filters: []*pb.SearchFilter{
        {Field: "status", Operator: pb.SearchOperator_EQUALS, Value: "active"},
        {Field: "years_exp", Operator: pb.SearchOperator_GREATER_THAN, Value: "5"},
    },
    OrderBy: "created_at",
    Desc:    true,
})
```

### Distributed Routing

Transparent RPC routing across collectors:

```go
// Client calls Collector A
resp, _ := client.Dispatch(ctx, &pb.DispatchRequest{
    Namespace:  "orders",
    Service:    &pb.ServiceTypeRef{ServiceName: "OrderService"},
    MethodName: "CreateOrder",
    Input:      orderData,
    // No target specified - auto-routes to appropriate collector
})

// resp.HandledByCollectorId tells you which collector executed it
fmt.Printf("Executed by: %s\n", resp.HandledByCollectorId)
```

### Backup and Replication ğŸ†•

**Point-in-time backups** without collection metadata pollution:

```go
// Create backup
backupResp, _ := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath:     "/backups/users-2025-11-22.db",
    IncludeFiles: true,
    Metadata:     map[string]string{"retention": "30d"},
})

// List backups
listResp, _ := client.ListBackups(ctx, &pb.ListBackupsRequest{
    Collection: &pb.NamespacedName{Namespace: "prod", Name: "users"},
    Limit:      10,
})

// Restore from backup
restoreResp, _ := client.RestoreBackup(ctx, &pb.RestoreBackupRequest{
    BackupId:      backupResp.Backup.BackupId,
    DestNamespace: "prod",
    DestName:      "users",
})
```

**Collection cloning** for testing and migration:

```go
// Local clone (within same collector)
cloneResp, _ := client.Clone(ctx, &pb.CloneRequest{
    SourceCollection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestNamespace: "staging",
    DestName:      "users-test",
    IncludeFiles:  true,
})

// Remote clone (to another collector)
cloneResp, _ := client.Clone(ctx, &pb.CloneRequest{
    SourceCollection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestEndpoint:  "collector2:50051",  // Remote target
    DestNamespace: "prod",
    DestName:      "users",
})

// Fetch from remote (pull collection)
fetchResp, _ := client.Fetch(ctx, &pb.FetchRequest{
    SourceEndpoint: "collector1:50051",
    SourceCollection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestNamespace: "prod",
    DestName:      "users-mirror",
})
```

**Key capabilities:**
- âœ… **Near-zero downtime** during backup (6-14ms lock time, proven with tests)
- âœ… **Concurrent operations** during backup (400+ reads/sec, 25+ writes/sec)
- âœ… **Streaming transfers** for large collections (1MB chunks)
- âœ… **Integrity verification** (SQLite PRAGMA checks)
- âœ… **Retention management** (list, delete old backups)

See: [Backup API Documentation](docs/features/backup-api.md) | [Clone & Fetch Guide](docs/features/clone-and-fetch.md)

## Data Model

### Collections

Collections are like database tables for protobuf messages:

```
Collection: production/users
  â”œâ”€ Store: SQLite with JSONB + FTS5
  â”‚   â”œâ”€ user-123: {name: "Alice", email: "alice@example.com"}
  â”‚   â”œâ”€ user-456: {name: "Bob", email: "bob@example.com"}
  â”‚   â””â”€ ...
  â”‚
  â””â”€ FileSystem: Hierarchical file storage
      â”œâ”€ user-123/
      â”‚   â”œâ”€ profile.jpg
      â”‚   â””â”€ documents/
      â”‚       â”œâ”€ resume.pdf
      â”‚       â””â”€ cover-letter.pdf
      â””â”€ user-456/
          â””â”€ avatar.png
```

### Registry Storage

Registry stores type information in collections:

```
RegisteredProtos Collection (system namespace)
  â””â”€ production/User â†’ FileDescriptorProto + metadata

RegisteredServices Collection (system namespace)
  â””â”€ production/CollectionService â†’ ServiceDescriptorProto + methods
```

## Design Philosophy

### Everything is Namespaced

Namespaces provide the fundamental isolation boundary:
- Data is scoped to namespaces
- Services are registered per namespace
- Validation is namespace-specific
- Routing respects namespace boundaries

### Strong Typing with Dynamic Dispatch

- All messages are typed (protobuf)
- All services are registered (type-checked)
- But invocation is dynamic (runtime dispatch)
- Best of both worlds: safety + flexibility

### gRPC All the Way Down

- Service-to-service communication via gRPC (even same-server)
- Interceptors apply uniformly
- Same code path for local and remote
- Proper observability and middleware

### Collection-Oriented Storage

- Registry stores service definitions in collections
- Collections store user data
- Collections can contain collections
- Uniform interface for all data

## Testing

**âš ï¸ IMPORTANT: Testing Requirements**

**Before making ANY changes, run the comprehensive test suite:**

```bash
./RUN_ALL_TESTS_BEFORE_SUBMIT.sh
```

This is **mandatory** for:
- âœ… All code changes
- âœ… All pull requests
- âœ… All AI agent contributions
- âœ… All manual development

**For AI Agents:** See [AGENTS.md](AGENTS.md) for detailed guidelines. Any test failure is YOUR responsibility to fix.

### Comprehensive Test Suite (REQUIRED)

**Always run the full test suite before submitting changes:**

```bash
./RUN_ALL_TESTS_BEFORE_SUBMIT.sh
```

This script runs:
- âœ… Build verification
- âœ… Code quality checks (go vet, go fmt)
- âœ… All unit tests
- âœ… Integration tests
- âœ… Backup system validation
- âœ… Concurrency & race detection
- âœ… Durability tests
- âœ… Benchmarks
- âœ… Coverage report

### Running Individual Test Suites

For development and debugging:

```bash
# Run all tests
go test ./pkg/... -v

# Run specific package tests
go test ./pkg/registry/... -v
go test ./pkg/dispatch/... -v
go test ./pkg/collection/... -v

# Run backup tests
go test ./pkg/collection -run "Test.*Backup" -v

# Run SQLite backup/availability tests
go test ./pkg/db/sqlite -run TestBackup -v

# Run integration tests
go test ./pkg/integration/... -v

# Race detection
go test ./pkg/... -race -short
```

**Test Statistics:**
- **230+ tests total** (215 existing + 15 new backup/availability tests)
- All packages: **100% passing**
- **14 backup-specific tests** - CRUD, concurrency, large datasets, special characters
- **7 backup availability tests** - Proven near-zero downtime with concurrent operations
- Integration tests validate multi-collector scenarios
- End-to-end tests prove full system integration

**Backup Availability Proof** (measured results):
- âœ… **402-641 concurrent reads** during backup with 0 errors
- âœ… **24-40 concurrent writes** during backup with 0 errors
- âœ… **6-14ms lock duration** (well below 50-200ms thresholds)
- âœ… **Production load test**: 340 reads + 25 writes simultaneously, all successful

See: [Backup Availability Test Results](docs/testing/backup-availability.md)

## Building

```bash
# Build the server
go build ./cmd/server

# Build and run
go run ./cmd/server/main.go

# Generate protobuf code (if proto files change)
./scripts/gen-proto.sh
```

## Project Structure

```
collector/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ server/          # Main server executable
â”‚       â””â”€â”€ main.go
â”‚
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ registry/        # Service registry and validation
â”‚   â”‚   â”œâ”€â”€ registry.go
â”‚   â”‚   â”œâ”€â”€ interceptor.go
â”‚   â”‚   â”œâ”€â”€ helpers.go
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ collection/      # ORM and data storage
â”‚   â”‚   â”œâ”€â”€ collection.go
â”‚   â”‚   â”œâ”€â”€ collection_server.go
â”‚   â”‚   â”œâ”€â”€ repo.go
â”‚   â”‚   â”œâ”€â”€ grpc_server.go
â”‚   â”‚   â”œâ”€â”€ backup.go            # ğŸ†• Backup manager
â”‚   â”‚   â”œâ”€â”€ backup_test.go       # ğŸ†• Backup tests (14 tests)
â”‚   â”‚   â”œâ”€â”€ clone.go             # ğŸ†• Clone/fetch operations
â”‚   â”‚   â”œâ”€â”€ transport.go         # ğŸ†• Data transport layer
â”‚   â”‚   â”œâ”€â”€ fetch.go             # ğŸ†• Remote fetching
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ dispatch/        # Distributed routing
â”‚   â”‚   â”œâ”€â”€ dispatcher.go
â”‚   â”‚   â”œâ”€â”€ connection.go
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ sqlite/      # SQLite backend
â”‚   â”‚       â”œâ”€â”€ store.go
â”‚   â”‚       â””â”€â”€ backup_test.go   # ğŸ†• Availability tests (7 tests)
â”‚   â”‚
â”‚   â”œâ”€â”€ fs/              # ğŸ†• Filesystem abstraction
â”‚   â”‚   â””â”€â”€ local/       # ğŸ†• Local filesystem implementation
â”‚   â”‚
â”‚   â””â”€â”€ integration/     # Integration tests
â”‚       â”œâ”€â”€ e2e_test.go
â”‚       â””â”€â”€ multi_collector_test.go
â”‚
â”œâ”€â”€ proto/               # Protocol buffer definitions
â”‚   â”œâ”€â”€ common.proto
â”‚   â”œâ”€â”€ collection.proto
â”‚   â”œâ”€â”€ collection_repo.proto    # ğŸ†• Backup/Clone RPCs added
â”‚   â”œâ”€â”€ dispatch.proto
â”‚   â””â”€â”€ registry.proto
â”‚
â”œâ”€â”€ gen/                 # Generated protobuf code
â”‚   â””â”€â”€ collector/
â”‚
â”œâ”€â”€ docs/                # ğŸ†• Organized documentation
â”‚   â”œâ”€â”€ README.md        # ğŸ†• Documentation index
â”‚   â”œâ”€â”€ features/        # ğŸ†• Feature guides
â”‚   â”‚   â”œâ”€â”€ backup-api.md          # ğŸ†• Backup API documentation
â”‚   â”‚   â””â”€â”€ clone-and-fetch.md     # ğŸ†• Clone/Fetch guide
â”‚   â”œâ”€â”€ architecture/    # ğŸ†• System design docs
â”‚   â””â”€â”€ testing/         # ğŸ†• Test results
â”‚       â””â”€â”€ backup-availability.md # ğŸ†• Availability proof
â”‚
â””â”€â”€ data/                # Runtime data (created at startup)
    â”œâ”€â”€ registry/        # Registry collections
    â”œâ”€â”€ repo/            # Collection repository
    â”œâ”€â”€ backups/         # ğŸ†• Backup storage
    â”‚   â””â”€â”€ metadata.db  # ğŸ†• Backup metadata tracking
    â””â”€â”€ files/           # File attachments
```

## Use Cases

### 1. Multi-Tenant SaaS

```go
// Each tenant gets their own namespace
for _, tenant := range tenants {
    // Register services per tenant
    registry.RegisterCollectionService(ctx, registryServer, tenant.ID)

    // Create tenant-specific collections
    collectionRepo.CreateCollection(ctx, &pb.CreateCollectionRequest{
        Collection: &pb.Collection{
            Namespace:   tenant.ID,
            Name:        "users",
            MessageType: "app.User",
        },
    })
}
```

### 2. Dynamic API Server

```go
// Register a new message type at runtime
registryClient.RegisterProto(ctx, &pb.RegisterProtoRequest{
    Namespace:      "production",
    FileDescriptor: newProtoDescriptor,
})

// Create a collection for it
collectionRepo.CreateCollection(ctx, &pb.CreateCollectionRequest{
    Collection: &pb.Collection{
        Namespace:   "production",
        Name:        "new-entity",
        MessageType: "app.NewEntity",
    },
})

// CRUD API is immediately available!
```

### 3. Distributed Microservices

```go
// Collector 1: User service
dispatcher1.RegisterService("users", "UserService", "GetUser", getUserHandler)

// Collector 2: Order service
dispatcher2.RegisterService("orders", "OrderService", "CreateOrder", createOrderHandler)

// Connect collectors
dispatcher1.ConnectTo(ctx, "collector2:50052", []string{"users", "orders"})

// Client calls Collector 1, transparently routes to Collector 2 when needed
```

### 4. Agent/LLM Backend

Dynamic dispatch and reflection make Collector ideal for agent systems:
- Register new capabilities as protobuf messages
- Agents discover available operations via registry
- Type-safe invocation with runtime flexibility
- Search across structured agent memory (collections)

## Security Considerations

**âš ï¸ Important**: Allowing clients to register types and invoke arbitrary methods is powerful but dangerous. Use in controlled environments or with additional security layers:

1. **Sandboxed Execution**: Run `Serve` methods in containers
2. **Authentication**: Add auth interceptors to gRPC servers
3. **Authorization**: Validate namespace access per user/tenant
4. **Rate Limiting**: Limit registration and RPC frequency
5. **Input Validation**: Validate all inputs in service handlers

The Dispatcher's `Serve` method is designed as an extension point for adding security controls.

## Performance

### Benchmarks

- **CRUD operations**: ~1-2ms per operation
- **Full-text search**: ~10-50ms for 100k records
- **Loopback gRPC**: ~100Î¼s-1ms overhead
- **Remote gRPC**: ~10-100ms depending on network

### Scaling

- **Vertical**: SQLite WAL mode enables high concurrency
- **Horizontal**: Add collectors, connect via Dispatcher
- **Sharding**: Use namespaces to partition data
- **Caching**: Registry lookups can be cached

## Roadmap

### Near Term
- [ ] Add dedicated `ValidateMethod` RPC to Registry
- [ ] Implement caching for registry validation
- [ ] Health checks via loopback connections
- [ ] Metrics and distributed tracing

### Future
- [ ] CollectiveWorker workflow system
- [ ] Cross-collector registry replication
- [ ] Query optimizer for complex searches
- [ ] Schema evolution and migrations
- [ ] Streaming APIs for large result sets

## Contributing

This is an experimental framework exploring new patterns in distributed systems. Feedback, issues, and contributions welcome!

## License

[Add your license here]

## For LLMs, Agents, and Developers

Collector is built for all three:
- **LLMs**: Use natural language to describe data models, get type-safe storage
- **Agents**: Discover capabilities via registry, invoke operations dynamically
- **Developers**: Build distributed systems with strong typing and minimal boilerplate

The framework bridges human intent, AI capabilities, and production systems through a unified protobuf-based interface.

---

**Ready to build?** Start with `go run ./cmd/server/main.go` and explore the package READMEs for deep dives into each service.
