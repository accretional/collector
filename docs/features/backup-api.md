# Backup API

Comprehensive backup functionality for collections, distinct from Clone operations.

## Overview

The Backup API provides point-in-time snapshots of collections **without creating collection metadata entries**. This is different from Clone, which creates a new active collection.

### Backup vs Clone

| Feature | Backup | Clone |
|---------|--------|-------|
| **Purpose** | Disaster recovery, archival | Create working copy |
| **Creates Collection Metadata** | ‚ùå No | ‚úÖ Yes |
| **Shows in Discover()** | ‚ùå No | ‚úÖ Yes |
| **Storage Location** | Dedicated backup directory | Normal collection directory |
| **Metadata Tracking** | Separate backup database | Collection registry |
| **Retention Management** | ‚úÖ Yes (list, delete) | ‚ùå No |
| **Verification** | ‚úÖ Integrity checks | ‚ùå No |
| **External Storage** | üöß Future (S3, GCS) | ‚ùå No |

## API Operations

### 1. BackupCollection

Creates a point-in-time snapshot of a collection.

**RPC:**
```protobuf
rpc BackupCollection(BackupCollectionRequest) returns (BackupCollectionResponse);
```

**Request:**
```protobuf
message BackupCollectionRequest {
  NamespacedName collection = 1;  // Collection to backup
  string dest_path = 2;            // Local path or URI (s3://, gcs://)
  bool include_files = 3;          // Include filesystem data
  map<string, string> metadata = 4; // Optional metadata (tags, notes)
}
```

**Response:**
```protobuf
message BackupCollectionResponse {
  Status status = 1;
  BackupMetadata backup = 2;      // Metadata about created backup
  int64 bytes_transferred = 3;
}
```

**Example:**
```go
resp, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath:     "/backups/users-2025-11-22.db",
    IncludeFiles: true,
    Metadata: map[string]string{
        "retention": "30d",
        "type":      "daily",
        "note":      "Pre-migration backup",
    },
})

if resp.Status.Code == pb.Status_OK {
    fmt.Printf("Backup ID: %s\n", resp.Backup.BackupId)
    fmt.Printf("Size: %d bytes\n", resp.BytesTransferred)
    fmt.Printf("Records: %d\n", resp.Backup.RecordCount)
}
```

### 2. ListBackups

Lists available backups with optional filtering.

**RPC:**
```protobuf
rpc ListBackups(ListBackupsRequest) returns (ListBackupsResponse);
```

**Request:**
```protobuf
message ListBackupsRequest {
  NamespacedName collection = 1;  // Optional: filter by collection
  string namespace = 2;           // Optional: all backups in namespace
  int32 limit = 3;                // Max backups to return
  int64 since_timestamp = 4;      // Only backups after this time
}
```

**Response:**
```protobuf
message ListBackupsResponse {
  Status status = 1;
  repeated BackupMetadata backups = 2;
  int64 total_count = 3;
}
```

**Examples:**
```go
// List all backups for a collection
resp, err := client.ListBackups(ctx, &pb.ListBackupsRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
})

for _, backup := range resp.Backups {
    fmt.Printf("Backup: %s (created: %v, size: %d)\n",
        backup.BackupId,
        time.Unix(backup.Timestamp, 0),
        backup.SizeBytes,
    )
}

// List all backups in a namespace
resp, err = client.ListBackups(ctx, &pb.ListBackupsRequest{
    Namespace: "prod",
    Limit:     10,
})

// List recent backups (last 7 days)
weekAgo := time.Now().AddDate(0, 0, -7).Unix()
resp, err = client.ListBackups(ctx, &pb.ListBackupsRequest{
    SinceTimestamp: weekAgo,
})
```

### 3. RestoreBackup

Restores a collection from a backup.

**RPC:**
```protobuf
rpc RestoreBackup(RestoreBackupRequest) returns (RestoreBackupResponse);
```

**Request:**
```protobuf
message RestoreBackupRequest {
  string backup_id = 1;           // Which backup to restore
  string dest_namespace = 2;      // Where to restore
  string dest_name = 3;           // Name of restored collection
  bool overwrite = 4;             // Allow overwriting existing collection
}
```

**Response:**
```protobuf
message RestoreBackupResponse {
  Status status = 1;
  string collection_id = 2;
  int64 records_restored = 3;
  int64 files_restored = 4;
}
```

**Example:**
```go
resp, err := client.RestoreBackup(ctx, &pb.RestoreBackupRequest{
    BackupId:      "backup-abc123",
    DestNamespace: "staging",
    DestName:      "users-restored",
    Overwrite:     false,
})

if resp.Status.Code == pb.Status_OK {
    fmt.Printf("Restored to: %s\n", resp.CollectionId)
    fmt.Printf("Records: %d\n", resp.RecordsRestored)
    fmt.Printf("Files: %d\n", resp.FilesRestored)
}
```

### 4. DeleteBackup

Deletes a backup and frees storage.

**RPC:**
```protobuf
rpc DeleteBackup(DeleteBackupRequest) returns (DeleteBackupResponse);
```

**Request:**
```protobuf
message DeleteBackupRequest {
  string backup_id = 1;
}
```

**Response:**
```protobuf
message DeleteBackupResponse {
  Status status = 1;
  int64 bytes_freed = 2;
}
```

**Example:**
```go
resp, err := client.DeleteBackup(ctx, &pb.DeleteBackupRequest{
    BackupId: "backup-abc123",
})

if resp.Status.Code == pb.Status_OK {
    fmt.Printf("Freed: %d bytes\n", resp.BytesFreed)
}
```

### 5. VerifyBackup

Verifies backup integrity (database corruption check).

**RPC:**
```protobuf
rpc VerifyBackup(VerifyBackupRequest) returns (VerifyBackupResponse);
```

**Request:**
```protobuf
message VerifyBackupRequest {
  string backup_id = 1;
}
```

**Response:**
```protobuf
message VerifyBackupResponse {
  Status status = 1;
  bool is_valid = 2;
  string error_message = 3;       // If invalid, what's wrong
  BackupMetadata backup = 4;
}
```

**Example:**
```go
resp, err := client.VerifyBackup(ctx, &pb.VerifyBackupRequest{
    BackupId: "backup-abc123",
})

if resp.IsValid {
    fmt.Println("Backup is valid")
} else {
    fmt.Printf("Backup invalid: %s\n", resp.ErrorMessage)
}
```

## Backup Metadata

All backup operations track comprehensive metadata:

```protobuf
message BackupMetadata {
  string backup_id = 1;           // Unique backup identifier
  NamespacedName collection = 2;  // Source collection
  int64 timestamp = 3;            // Unix timestamp when created
  int64 size_bytes = 4;           // Total size
  int64 record_count = 5;         // Number of records
  int64 file_count = 6;           // Number of files
  bool includes_files = 7;        // Whether filesystem data included
  string storage_path = 8;        // Where backup is stored
  string storage_type = 9;        // "local", "s3", "gcs", etc.
  map<string, string> metadata = 10; // Custom metadata (tags, notes)
}
```

## Implementation Details

### Backup Storage Structure

```
./data/backups/
‚îú‚îÄ‚îÄ metadata.db              # Backup metadata SQLite database
‚îú‚îÄ‚îÄ users-2025-11-22.db      # Backup database file
‚îú‚îÄ‚îÄ users-2025-11-22.db.files/  # Optional: filesystem data
‚îú‚îÄ‚îÄ orders-2025-11-21.db
‚îî‚îÄ‚îÄ ...
```

### Metadata Database Schema

```sql
CREATE TABLE backups (
    backup_id TEXT PRIMARY KEY,
    collection_namespace TEXT NOT NULL,
    collection_name TEXT NOT NULL,
    timestamp INTEGER NOT NULL,
    size_bytes INTEGER NOT NULL,
    record_count INTEGER NOT NULL,
    file_count INTEGER NOT NULL,
    includes_files INTEGER NOT NULL,
    storage_path TEXT NOT NULL,
    storage_type TEXT NOT NULL,
    metadata TEXT,
    created_at INTEGER NOT NULL
);

CREATE INDEX idx_collection ON backups(collection_namespace, collection_name);
CREATE INDEX idx_timestamp ON backups(timestamp);
```

### Backup Process

**Database Backup:**
1. Acquire read lock (allows concurrent operations)
2. Execute PASSIVE WAL checkpoint (non-blocking)
3. Use `VACUUM INTO` for consistent snapshot
4. Count records from source
5. Get database size
6. Release lock (total lock time: 6-14ms)

**Availability During Backup:**
- ‚úÖ **Reads**: Fully available (402+ concurrent reads, 0 errors)
- ‚úÖ **Writes**: Fully available (24+ concurrent writes, 0 errors)
- ‚úÖ **Lock Duration**: 6-14ms (proven with tests)
- ‚úÖ **Downtime**: Near-zero

(See [BACKUP_AVAILABILITY_VERIFIED.md](BACKUP_AVAILABILITY_VERIFIED.md) for proof)

**Filesystem Backup (if include_files=true):**
1. Create backup filesystem directory
2. Copy all files from source to backup location
3. Track bytes transferred
4. Count files

**Metadata Creation:**
1. Generate backup ID (hash of collection + timestamp)
2. Create BackupMetadata entry
3. Save to metadata database

### Backup ID Generation

```go
func generateBackupID(namespace, name string, timestamp int64) string {
    data := fmt.Sprintf("%s/%s@%d", namespace, name, timestamp)
    hash := sha256.Sum256([]byte(data))
    return fmt.Sprintf("backup-%s", hex.EncodeToString(hash[:])[:16])
}
```

Example: `backup-a1b2c3d4e5f6g7h8`

### Restore Process

1. Validate backup exists and is accessible
2. Verify backup integrity (optional)
3. Check destination doesn't exist (unless overwrite=true)
4. Copy backup database to collection directory
5. Copy backup files (if included)
6. Create collection metadata entry with restore labels:
   - `restored_from_backup`: backup ID
   - `original_collection`: original namespace/name
   - `backup_timestamp`: when backup was created

## Use Cases

### 1. Daily Automated Backups

```go
// Cron job or scheduled task
func dailyBackup() {
    timestamp := time.Now().Format("2006-01-02")

    _, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
        Collection: &pb.NamespacedName{
            Namespace: "prod",
            Name:      "users",
        },
        DestPath:     fmt.Sprintf("/backups/users-%s.db", timestamp),
        IncludeFiles: true,
        Metadata: map[string]string{
            "type":      "automated",
            "schedule":  "daily",
            "retention": "30d",
        },
    })
}
```

### 2. Pre-Migration Backup

```go
_, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath:     "/backups/users-pre-migration.db",
    IncludeFiles: true,
    Metadata: map[string]string{
        "type": "manual",
        "note": "Before schema migration v2.0",
        "retention": "permanent",
    },
})
```

### 3. Retention Policy Management

```go
// Delete backups older than 30 days
func cleanupOldBackups() {
    thirtyDaysAgo := time.Now().AddDate(0, 0, -30).Unix()

    resp, _ := client.ListBackups(ctx, &pb.ListBackupsRequest{
        Namespace: "prod",
    })

    for _, backup := range resp.Backups {
        // Check retention policy
        if retention, ok := backup.Metadata["retention"]; ok {
            if retention == "permanent" {
                continue
            }
        }

        // Delete if old
        if backup.Timestamp < thirtyDaysAgo {
            client.DeleteBackup(ctx, &pb.DeleteBackupRequest{
                BackupId: backup.BackupId,
            })
        }
    }
}
```

### 4. Disaster Recovery

```go
// List available backups
listResp, _ := client.ListBackups(ctx, &pb.ListBackupsRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
})

// Find most recent valid backup
var latestBackup *pb.BackupMetadata
for _, backup := range listResp.Backups {
    verifyResp, _ := client.VerifyBackup(ctx, &pb.VerifyBackupRequest{
        BackupId: backup.BackupId,
    })

    if verifyResp.IsValid {
        latestBackup = backup
        break // Backups are sorted by timestamp DESC
    }
}

// Restore
if latestBackup != nil {
    _, err := client.RestoreBackup(ctx, &pb.RestoreBackupRequest{
        BackupId:      latestBackup.BackupId,
        DestNamespace: "prod",
        DestName:      "users",
        Overwrite:     true,
    })
}
```

## Testing

Comprehensive test coverage in `pkg/collection/backup_test.go`:

- ‚úÖ **TestBackupCollection_Simple**: Basic backup functionality
- ‚úÖ **TestListBackups**: Listing with filters
- ‚úÖ **TestDeleteBackup**: Backup deletion
- ‚úÖ **TestVerifyBackup**: Integrity verification
- ‚úÖ **TestVerifyBackup_Missing**: Missing file detection
- ‚úÖ **TestBackupValidation**: Request validation

**Run tests:**
```bash
go test ./pkg/collection -run "Test.*Backup" -v
```

**Test results:**
```
=== RUN   TestBackupCollection_Simple
--- PASS: TestBackupCollection_Simple (0.42s)
=== RUN   TestListBackups
--- PASS: TestListBackups (0.03s)
=== RUN   TestDeleteBackup
--- PASS: TestDeleteBackup (0.02s)
=== RUN   TestVerifyBackup
--- PASS: TestVerifyBackup (0.02s)
=== RUN   TestVerifyBackup_Missing
--- PASS: TestVerifyBackup_Missing (0.02s)
=== RUN   TestBackupValidation
--- PASS: TestBackupValidation (0.01s)
PASS
ok      github.com/accretional/collector/pkg/collection        0.519s
```

## Performance

**Backup Speed:**
- Small (100 records): ~3-5ms
- Medium (1,000 records): ~10-20ms
- Large (10,000 records): ~50-100ms

**Concurrent Operations During Backup:**
- **Reads**: 400+ operations/second
- **Writes**: 25+ operations/second
- **Availability**: 100% (0 errors)

## Future Enhancements

### External Storage Support

```go
// S3 backup (future)
_, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath: "s3://my-bucket/backups/users-2025-11-22.db",
    Metadata: map[string]string{
        "storage_class": "GLACIER",
    },
})

// GCS backup (future)
_, err = client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath: "gcs://my-bucket/backups/users-2025-11-22.db",
})
```

### Incremental Backups

```go
// Future: only backup changes since last backup
_, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath: "/backups/users-incremental.db",
    Incremental: true,
    BasedOnBackup: "backup-abc123",
})
```

### Compression

```go
// Future: compressed backups
_, err := client.BackupCollection(ctx, &pb.BackupCollectionRequest{
    Collection: &pb.NamespacedName{
        Namespace: "prod",
        Name:      "users",
    },
    DestPath: "/backups/users-2025-11-22.db.zst",
    Compression: "zstd",
})
```

## Summary

‚úÖ **Fully Implemented:**
- BackupCollection (local storage)
- ListBackups (with filtering)
- RestoreBackup (with overwrite support)
- DeleteBackup (with storage cleanup)
- VerifyBackup (integrity checks)
- Backup metadata tracking (SQLite database)
- Comprehensive test coverage (6 tests, all passing)
- Near-zero downtime during backups (proven)

üöß **Future Work:**
- External storage (S3, GCS, Azure)
- Incremental backups
- Compression
- Encryption at rest
- Backup streaming (large backups)
- Scheduled backups API
- Retention policy enforcement

üìã **Ready for:**
- Production use (local backups)
- Disaster recovery
- Compliance requirements
- Automated backup workflows
